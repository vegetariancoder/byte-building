{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Process the Customers Data\n",
    "1. Ingest the data into the data lakehouse - stg_customers\n",
    "2. Perform data quality checks and transform the data as required - stg_customers_clean\n",
    "3. Apply changes to the Customers data - raw_customers"
   ],
   "id": "e6c9c3429e80af44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, current_timestamp, current_date"
   ],
   "id": "478564ad7d8b759e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Ingest the data into the data lakehouse - stg_customers",
   "id": "d2c2b39d225cbef9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dlt.table(\n",
    "    name=\"stg_customers\",  # you can assign a schema name here as well: <schema_name>.bronze_customers\n",
    "    comment=\"The customers data ingested from the customer's data lakehouse.\",\n",
    "    table_properties={\n",
    "        \"quality\": \"staging\",\n",
    "        \"delta.autoOptimize.optimizeWrite\": \"true\"\n",
    "    }\n",
    "    # path = \"location to store delta table\"\n",
    ")\n",
    "def stg_customers():\n",
    "    \"\"\"Ingest the customer's data into the bronze table.\"\"\"\n",
    "    df_stg_customer = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"cloudFiles\") \\\n",
    "        .option(\"cloudFiles.format\", \"json\") \\\n",
    "        .option(\"cloudFiles.inferSchema\", \"true\") \\\n",
    "        .option(\"cloudFiles.inferColumnTypes\", \"true\") \\\n",
    "        .option(\"cloudFiles.schemaLocation\", \"/Volumes/circuitbox/landing/operational_data/schema/customers/\") \\\n",
    "        .load(\"/Volumes/circuitbox/landing/operational_data/customers/\")\n",
    "\n",
    "    df_stg_customer = df_stg_customer \\\n",
    "        .withColumn(\"input_file_path\", col(\"_metadata.file_path\")) \\\n",
    "        .withColumn(\"ingest_timestamp\", current_timestamp()) \\\n",
    "        .withColumn(\"load_date\", current_date())\n",
    "\n",
    "    return df_stg_customer"
   ],
   "id": "5fbf49e67ec3c6d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Perform data quality checks and transform the data as required - stg_customers_clean",
   "id": "1e9ce581b00a09be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dlt.table(\n",
    "    name=\"stg_customers_clean\",\n",
    "    comment=\"The customers data after data quality checks and transformation.\",\n",
    "    table_properties={\n",
    "        \"quality\": \"staging\",\n",
    "        \"delta.autoOptimize.optimizeWrite\": \"true\"\n",
    "    }\n",
    ")\n",
    "@dlt.expect_or_fail(\"valid_customer_id\", \"customer_id IS NOT NULL\")\n",
    "@dlt.expect_or_drop(\"valid_customer_name\", \"customer_name IS NOT NULL\")\n",
    "@dlt.expect(\"length_telephone\", \"LENGTH(telephone)>=10\")\n",
    "@dlt.expect(\"valid_email\", \"email IS NOT NULL\")\n",
    "def stg_customers_clean():\n",
    "    \"\"\"Perform data quality checks and transform the data as required.\"\"\"\n",
    "\n",
    "    df_stg_customers_clean = spark \\\n",
    "        .readStream \\\n",
    "        .table(\"LIVE.stg_customers\") \\\n",
    "        .select(\n",
    "        \"customer_id\",\n",
    "        \"customer_name\",\n",
    "        col(\"date_of_birth\").cast(\"date\"),\n",
    "        \"telephone\",\n",
    "        \"email\",\n",
    "        col(\"created_date\").cast(\"date\"),\n",
    "    ) \\\n",
    "        .withColumn(\"ingest_timestamp\", current_timestamp()) \\\n",
    "        .withColumn(\"load_date\", current_date())\n",
    "\n",
    "    return df_stg_customers_clean"
   ],
   "id": "5677cd455b061c76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3. Apply changes to the Customers data - raw_customers",
   "id": "962cf0c6264f2d58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dlt.create_streaming_table(\n",
    "    name = \"raw_customers\",\n",
    "    comment = \"SCD Type 1 customers data\",\n",
    "    table_properties = {'quality' : 'raw'}\n",
    ")\n",
    "\n",
    "dlt.apply_changes(\n",
    "    target=\"raw_customers\",\n",
    "    source=\"stg_customers_clean\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=\"created_date\",\n",
    "    stored_as_scd_type=1\n",
    ")"
   ],
   "id": "370df6ae4efd3392"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
